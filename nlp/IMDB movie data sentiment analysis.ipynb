{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc",
   "display_name": "Python 3.9.1 64-bit ('python@3.9')"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "source": [
    "# Text normalization\n",
    "## tokenization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re, string, unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/admin/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = ToktokTokenizer()\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the noisy text\n",
    "def noiseremoval_text(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(noiseremoval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. The filming tec...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. The filming tec...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "source": [
    "# Stemming"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other review ha mention that after ...  positive\n",
       "1  a wonder littl production. the film techniqu i...  positive\n",
       "2  i thought thi wa a wonder way to spend time on...  positive\n",
       "3  basic there' a famili where a littl boy (jake)...  negative\n",
       "4  petter mattei' \"love in the time of money\" is ...  positive"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one of the other review ha mention that after ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a wonder littl production. the film techniqu i...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i thought thi wa a wonder way to spend time on...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basic there' a famili where a littl boy (jake)...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter mattei' \"love in the time of money\" is ...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "source": [
    "# Removing stop words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'very', 'wouldn', 'such', \"don't\", 'in', 'was', \"aren't\", \"doesn't\", 'herself', 'won', \"mustn't\", 'doesn', \"weren't\", 'doing', 'will', 'didn', 'this', 'with', 'am', 'at', \"wouldn't\", 'have', 'm', \"didn't\", 'most', 'how', 'its', 'below', 'and', 'these', 'further', 'did', 'yourself', \"that'll\", 'having', 'after', 'needn', \"isn't\", 'them', 'are', 'where', 'only', 'those', 'don', 'your', 'he', 'so', 'our', 'that', 'ma', \"hadn't\", 'for', 'couldn', 'ourselves', 'yourselves', 'any', \"you're\", 'ain', 'do', 'who', 'it', 'if', 'above', 'few', 'o', 'all', \"shouldn't\", 'wasn', 'other', 'down', 'why', 'own', 'same', 'she', 'itself', 'on', 'there', 'of', 'is', 'through', 'y', 'an', \"needn't\", 'weren', \"she's\", 'nor', 'yours', 'hers', 'they', 'not', 'i', 'over', 'but', 'once', 're', 'd', 'mightn', 'about', \"you'd\", 'the', \"mightn't\", 'here', 'himself', 'from', 'out', \"you've\", 'because', 'me', 'his', 'being', \"you'll\", 'between', 'no', \"wasn't\", \"won't\", 'a', 'themselves', 'too', 'which', 'each', 'should', \"haven't\", 'before', \"should've\", 's', 'up', 'ours', 'more', 'isn', 'has', 'be', 'both', 'while', 'or', 'my', 'now', 'mustn', 'their', 'then', 'we', 'haven', 'again', 'whom', \"couldn't\", 'off', 'does', \"shan't\", 'you', 'until', \"hasn't\", 'what', 'shouldn', 'to', \"it's\", 'hasn', 'him', 'aren', 'some', 'than', 'shan', 'just', 'hadn', 'were', 'her', 'theirs', 'as', 'during', 't', 'against', 'by', 'had', 'll', 'under', 've', 'can', 'when', 'into', 'myself', 'been'}\n"
     ]
    }
   ],
   "source": [
    "stop_wr = set(stopwords.words('english'))\n",
    "print(stop_wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_stopwords(text, is_lower_case = False):\n",
    "    tokenizers = ToktokTokenizer()\n",
    "    tokens = tokenizers.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filter_tokens = [token for token in tokens if token not in stop_wr]\n",
    "    else:\n",
    "        filter_tokens = [token for token in tokens if token.lower() not in stop_wr]\n",
    "        filtered_text = ' '.join(filter_tokens)\n",
    "        return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(removing_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  one review ha mention watch 1 oz episod ' hook...  positive\n",
       "1  wonder littl production. film techniqu veri un...  positive\n",
       "2  thought thi wa wonder way spend time hot summe...  positive\n",
       "3  basic ' famili littl boy ( jake ) think ' zomb...  negative\n",
       "4  petter mattei ' \" love time money \" visual stu...  positive"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one review ha mention watch 1 oz episod ' hook...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wonder littl production. film techniqu veri un...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>thought thi wa wonder way spend time hot summe...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basic ' famili littl boy ( jake ) think ' zomb...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter mattei ' \" love time money \" visual stu...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "source": [
    "# Split training & test datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataset\n",
    "train_review_data = data.review[:30000]\n",
    "\n",
    "#test dataset\n",
    "test_review_data = data.review[30000:]"
   ]
  },
  {
   "source": [
    "# Bag of words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BOW_cv_train: (30000, 4954557)\nBOW_cv_test: (20000, 4954557)\n"
     ]
    }
   ],
   "source": [
    "#count vectorizer for bag of words\n",
    "cv = CountVectorizer(min_df=0, max_df=1, binary=False, ngram_range=(1,3))\n",
    "\n",
    "#transformed train reviews\n",
    "cv_train = cv.fit_transform(train_review_data)\n",
    "\n",
    "#transformed test reviews\n",
    "cv_test = cv.transform(test_review_data)\n",
    "\n",
    "print('BOW_cv_train:',cv_train.shape)\n",
    "print('BOW_cv_test:',cv_test.shape)"
   ]
  },
  {
   "source": [
    "# TF_IDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tfidf_train: (30000, 4954557)\nTfidf_test: (20000, 4954557)\n"
     ]
    }
   ],
   "source": [
    "#TF_IDF vectorizer\n",
    "tf = TfidfVectorizer(min_df=0, max_df=1, use_idf=True, ngram_range=(1,3))\n",
    "\n",
    "#transformed trian reviews\n",
    "tf_train = tf.fit_transform(train_review_data)\n",
    "\n",
    "#transformed test reviews\n",
    "tf_test = tf.transform(test_review_data)\n",
    "\n",
    "print('Tfidf_train:',tf_train.shape)\n",
    "print('Tfidf_test:',tf_test.shape)"
   ]
  },
  {
   "source": [
    "# Label encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "#labeling the sentient data\n",
    "label = LabelBinarizer()\n",
    "\n",
    "#transformed sentiment data\n",
    "sentiment_data = label.fit_transform(data['sentiment'])\n",
    "\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment_data = data.sentiment[:30000]\n",
    "\n",
    "test_sentiment_data = data.sentiment[30000:]"
   ]
  },
  {
   "source": [
    "# Training the mode"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n",
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=42)\n",
    "\n",
    "lr_bow = logistic.fit(cv_train, train_sentiment_data)\n",
    "print(lr_bow)\n",
    "\n",
    "lr_tfidf = logistic.fit(tf_train, train_sentiment_data)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['negative' 'negative' 'negative' ... 'negative' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "lr_bow_predict = logistic.predict(cv_test)\n",
    "print(lr_bow_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['negative' 'negative' 'negative' ... 'negative' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for tfidf fetures\n",
    "lr_tfidf_predict = logistic.predict(tf_test)\n",
    "print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lr_bow_score:  0.74255\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "lr_bow_score = accuracy_score(test_sentiment_data, lr_bow_predict)\n",
    "\n",
    "print(\"lr_bow_score: \", lr_bow_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lr_tfidf_score : 0.7426\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for tfidf features\n",
    "lr_tfidf_score=accuracy_score(test_sentiment_data,lr_tfidf_predict)\n",
    "print(\"lr_tfidf_score :\",lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}